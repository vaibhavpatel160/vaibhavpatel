{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiasDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavpatel160/vaibhavpatel/blob/main/BiasDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwA376535Yuy"
      },
      "source": [
        "# Task: Live Bias Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxqHOduUxmrL"
      },
      "source": [
        "# Task 1: Implement Google Speech to text in a live demo!\n",
        "(transcribe audio in near real-time and organize said transcription in a script that can be further analyzed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXjxbL2XMFUz"
      },
      "source": [
        "#Install dependencies\n",
        "!pip install --upgrade google-cloud-speech\n",
        "!pip install google-cloud-speech\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg  ## Only for google colab\n",
        "!pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM4Q2q-bI926"
      },
      "source": [
        "from google.cloud import speech_v1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GubZqGmFVA7U"
      },
      "source": [
        "import os\n",
        "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/drive/MyDrive/Colab Notebooks/googlecloud.json.json\"\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/googlecloud.json\"\n",
        "\n",
        "def implicit():\n",
        "    from google.cloud import storage\n",
        "\n",
        "    # If you don't specify credentials when constructing the client, the\n",
        "    # client library will look for credentials in the environment.\n",
        "    storage_client = storage.Client()\n",
        "    \n",
        "\n",
        "    # Make an authenticated API request\n",
        "    buckets = list(storage_client.list_buckets())\n",
        "    print(buckets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8IamrqoUffu"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjgAS95TH_fi",
        "outputId": "a078697c-97a0-4fc8-f7a5-e2075835fbc3"
      },
      "source": [
        "pip install --upgrade setuptools pip wheel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (59.4.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.3.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dIPmoShIiES"
      },
      "source": [
        "pip install google-cloud-pubsub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "b-JBCz5Qemba",
        "outputId": "a9402f48-00b1-4629-efcc-0c6306d4ce7b"
      },
      "source": [
        "import io\n",
        "import requests\n",
        "from google.cloud import speech\n",
        "client = speech.SpeechClient()\n",
        "config = speech_v1.types.RecognitionConfig(\n",
        "     encoding=speech.enum.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "     language_code='en-US',\n",
        "     sample_rate_hertz=44100,\n",
        ")\n",
        "with io.open('./hello.wav', 'rb') as stream:\n",
        "    requests = [speech.types.StreamingRecognizeRequest(\n",
        "        audio_content=stream.read(),\n",
        "    )]\n",
        "results = sample.streaming_recognize(\n",
        "    config=speech.types.StreamingRecognitionConfig(config=config) , requests = requests\n",
        ")\n",
        "for result in results:\n",
        "    for alternative in result.alternatives:\n",
        "        print('=' * 20)\n",
        "        print('transcript: ' + alternative.transcript)\n",
        "        print('confidence: ' + str(alternative.confidence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2c659203e9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m config = speech_v1.types.RecognitionConfig(\n\u001b[0;32m----> 6\u001b[0;31m      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognitionConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioEncoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINEAR16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m      \u001b[0mlanguage_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en-US'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m      \u001b[0msample_rate_hertz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m44100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'google.cloud.speech' has no attribute 'enum'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh87Ho8DVfgT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "f769b27c-0fda-4bc8-c245-9da193d87577"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import re\n",
        "import sys\n",
        "\n",
        "from google.cloud import speech\n",
        "\n",
        "import pyaudio\n",
        "from six.moves import queue\n",
        "\n",
        "# Audio recording parameters\n",
        "RATE = 16000\n",
        "CHUNK = int(RATE / 10)  # 100ms\n",
        "\n",
        "\n",
        "class MicrophoneStream(object):\n",
        "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
        "\n",
        "    def __init__(self, rate, chunk):\n",
        "        self._rate = rate\n",
        "        self._chunk = chunk\n",
        "\n",
        "        # Create a thread-safe buffer of audio data\n",
        "        self._buff = queue.Queue()\n",
        "        self.closed = True\n",
        "\n",
        "    def __enter__(self):\n",
        "        self._audio_interface = pyaudio.PyAudio()\n",
        "        self._audio_stream = self._audio_interface.open(\n",
        "            format=pyaudio.paInt16,\n",
        "            # The API currently only supports 1-channel (mono) audio\n",
        "            # https://goo.gl/z757pE\n",
        "            channels=1,\n",
        "            rate=self._rate,\n",
        "            input=True,\n",
        "            frames_per_buffer=self._chunk,\n",
        "            # Run the audio stream asynchronously to fill the buffer object.\n",
        "            # This is necessary so that the input device's buffer doesn't\n",
        "            # overflow while the calling thread makes network requests, etc.\n",
        "            stream_callback=self._fill_buffer\n",
        "        )\n",
        "\n",
        "        self.closed = False\n",
        "\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self._audio_stream.stop_stream()\n",
        "        self._audio_stream.close()\n",
        "        self.closed = True\n",
        "        # Signal the generator to terminate so that the client's\n",
        "        # streaming_recognize method will not block the process termination.\n",
        "        self._buff.put(None)\n",
        "        self._audio_interface.terminate()\n",
        "\n",
        "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
        "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
        "        self._buff.put(in_data)\n",
        "        return None, pyaudio.paContinue\n",
        "\n",
        "    def generator(self):\n",
        "        while not self.closed:\n",
        "            # Use a blocking get() to ensure there's at least one chunk of\n",
        "            # data, and stop iteration if the chunk is None, indicating the\n",
        "            # end of the audio stream.\n",
        "            chunk = self._buff.get()\n",
        "            if chunk is None:\n",
        "                return\n",
        "            data = [chunk]\n",
        "\n",
        "            # Now consume whatever other data's still buffered.\n",
        "            while True:\n",
        "                try:\n",
        "                    chunk = self._buff.get(block=False)\n",
        "                    if chunk is None:\n",
        "                        return\n",
        "                    data.append(chunk)\n",
        "                except queue.Empty:\n",
        "                    break\n",
        "\n",
        "            yield b\"\".join(data)\n",
        "\n",
        "\n",
        "def listen_print_loop(responses):\n",
        "    \"\"\"Iterates through server responses and prints them.\n",
        "\n",
        "    The responses passed is a generator that will block until a response\n",
        "    is provided by the server.\n",
        "\n",
        "    Each response may contain multiple results, and each result may contain\n",
        "    multiple alternatives; for details, see https://goo.gl/tjCPAU.  Here we\n",
        "    print only the transcription for the top alternative of the top result.\n",
        "\n",
        "    In this case, responses are provided for interim results as well. If the\n",
        "    response is an interim one, print a line feed at the end of it, to allow\n",
        "    the next result to overwrite it, until the response is a final one. For the\n",
        "    final one, print a newline to preserve the finalized transcription.\n",
        "    \"\"\"\n",
        "    num_chars_printed = 0\n",
        "    for response in responses:\n",
        "        if not response.results:\n",
        "            continue\n",
        "\n",
        "        # The `results` list is consecutive. For streaming, we only care about\n",
        "        # the first result being considered, since once it's `is_final`, it\n",
        "        # moves on to considering the next utterance.\n",
        "        result = response.results[0]\n",
        "        if not result.alternatives:\n",
        "            continue\n",
        "\n",
        "        # Display the transcription of the top alternative.\n",
        "        transcript = result.alternatives[0].transcript\n",
        "\n",
        "        # Display interim results, but with a carriage return at the end of the\n",
        "        # line, so subsequent lines will overwrite them.\n",
        "        #\n",
        "        # If the previous result was longer than this one, we need to print\n",
        "        # some extra spaces to overwrite the previous result\n",
        "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
        "\n",
        "        if not result.is_final:\n",
        "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            num_chars_printed = len(transcript)\n",
        "\n",
        "        else:\n",
        "            print(transcript + overwrite_chars)\n",
        "\n",
        "            # Exit recognition if any of the transcribed phrases could be\n",
        "            # one of our keywords.\n",
        "            if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
        "                print(\"Exiting..\")\n",
        "                break\n",
        "\n",
        "            num_chars_printed = 0\n",
        "\n",
        "\n",
        "def main():\n",
        "    # See http://g.co/cloud/speech/docs/languages\n",
        "    # for a list of supported languages.\n",
        "    language_code = \"en-US\"  # a BCP-47 language tag\n",
        "\n",
        "    client = speech.SpeechClient()\n",
        "    config = speech.RecognitionConfig(\n",
        "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "        sample_rate_hertz=RATE,\n",
        "        language_code=language_code,\n",
        "    )\n",
        "\n",
        "    streaming_config = speech.StreamingRecognitionConfig(\n",
        "        config=config, interim_results=True\n",
        "    )\n",
        "\n",
        "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
        "        audio_generator = stream.generator()\n",
        "        requests = (\n",
        "            speech.StreamingRecognizeRequest(audio_content=content)\n",
        "            for content in audio_generator\n",
        "        )\n",
        "\n",
        "        responses = client.streaming_recognize(streaming_config, requests)\n",
        "\n",
        "        # Now, put the transcription responses to use.\n",
        "        listen_print_loop(responses)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c6da13074134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-c6da13074134>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mMicrophoneStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0maudio_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         requests = (\n",
            "\u001b[0;32m<ipython-input-20-c6da13074134>\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# This is necessary so that the input device's buffer doesn't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# overflow while the calling thread makes network requests, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mstream_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fill_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyaudio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_streams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyaudio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# calling pa.open returns a stream object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_latency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputLatency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno -9996] Invalid input device (no default output device)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HEtfYVJIILj"
      },
      "source": [
        "# Task 2: Detect Racial slurs in transcription!\n",
        "Real time & Retroactive "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQktjnK5cGX"
      },
      "source": [
        "importing necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bkyNzfZ-obo"
      },
      "source": [
        "url=\"https://www.lifehack.org/articles/communication/common-words-use-that-hurt-others.html\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKN1JsY7_ASi"
      },
      "source": [
        "\n",
        "headers = {\n",
        "    'Access-Control-Allow-Origin': '*',\n",
        "    'Access-Control-Allow-Methods': 'GET',\n",
        "    'Access-Control-Allow-Headers': 'Content-Type',\n",
        "    'Access-Control-Max-Age': '3600',\n",
        "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "583lm_xu_atE"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "...\n",
        "url = \"https://codeforces.com/problemset\"\n",
        "req = requests.get(url, headers)\n",
        "soup = BeautifulSoup(req.content, 'html.parser')\n",
        "print(soup.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0GFcS6CAiEM"
      },
      "source": [
        "soup.find_all(\"div\" class=\"article-page container\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjQoVSRzArcA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}